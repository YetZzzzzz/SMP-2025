{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2531334-5fbe-45eb-a9a0-ed4e971f13d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 12:47:52.510291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-04 12:47:53.532927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-04 12:47:53.533015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-04 12:47:53.533026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "        \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c400266c-4caf-4d22-b5ea-2c4555966750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.11.0\n",
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "# tf setup\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print('Accelerated Linear Algebra enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77abc38-68c8-41f9-929f-f15fe401c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_STRATEGY = 'StratifiedGroupKFold' # GroupKFold, PurgedGroupTimeSeriesSplit\n",
    "SEED = 2021\n",
    "# START_DATE = 86\n",
    "FOLDS = 5\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae152551-1219-43df-b5c0-7112d7209303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb7c0334-3736-4386-8d2c-f58a7efcb5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# from scipy.stats import norm, skew\n",
    "# all_data = pd.read_csv('../data/forauto.csv')\n",
    "# useless_cols = ['Category.1', 'Concept.1', 'Subcategory.1', 'Alltags','Title','img_file']\n",
    "# cate_cols = ['Uid', 'Category', 'Subcategory', 'Concept', 'Mediatype', 'hour', 'day', 'weekday', 'week_hour',\n",
    "#              'Geoaccuracy', 'ispro' , 'Ispublic', 'img_model']\n",
    "# useless_cols += cate_cols\n",
    "# all_data = all_data.drop(useless_cols,axis=1)\n",
    "# # alltags = all_data[['Alltags','label']]\n",
    "# # alltags.columns = ['excerpt', 'target']\n",
    "# rob = pd.read_csv('./preRoberta_fea.csv')\n",
    "# all_data = pd.concat([all_data,rob],axis=1)\n",
    "# columns = ['Title_len', 'Title_number', 'Alltags_len', 'Alltags_number', 'photo_count', 'totalTags', 'totalGeotagged', 'totalFaves',\n",
    "#           'totalInGroup','photoCount','meanView', 'meanTags', 'meanFaves', 'followerCount','followingCount']\n",
    "\n",
    "# skew_features = all_data[columns].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "# high_skew = skew_features[abs(skew_features) > 0.75]\n",
    "# skew_index = high_skew.index\n",
    "# for i in skew_index:\n",
    "#     all_data[i] = np.log1p(all_data[i])\n",
    "    \n",
    "# train = all_data[:-180581]\n",
    "# test = all_data[-180581:]\n",
    "\n",
    "# # test = test.reset_index(drop=True)\n",
    "# y = train['label'].values\n",
    "# X = train.drop(['label'],axis=1).values\n",
    "\n",
    "# # alltags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd73284-5824-4db3-8c72-099b8237746b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "all_data = pd.read_csv('../data/forauto.csv')\n",
    "useless_cols = ['year_weekday', 'Longitude','Uid_count','img_length','img_width', 'pixel','Category.1', \n",
    "                'Concept.1', 'Subcategory.1', 'Alltags','Title','img_file','firstdate','firstweek', 'firstmonth', \n",
    "                'firstdatetaken', 'firstdatetakenweek','firstdatetakenmonth','totalViews']\n",
    "cate_cols = ['Uid', 'Category', 'Latitude', 'Geoaccuracy', 'Subcategory', 'Concept', 'Mediatype', \n",
    "             'hour', 'day', 'weekday', 'week_hour','Geoaccuracy', 'ispro' , 'Ispublic', 'img_model']\n",
    "useless_cols += cate_cols\n",
    "all_data = all_data.drop(useless_cols,axis=1)\n",
    "# alltags = all_data[['Alltags','label']]\n",
    "# alltags.columns = ['excerpt', 'target']\n",
    "rob = pd.read_csv('./preRoberta_fea.csv')\n",
    "all_data = pd.concat([all_data,rob],axis=1)\n",
    "columns = ['Title_len', 'Title_number', 'Alltags_len', 'Alltags_number', \n",
    "           'photo_count', 'totalTags', 'totalGeotagged', 'totalFaves',\n",
    "          'totalInGroup','photoCount','meanView', 'meanTags', 'meanFaves', 'followerCount','followingCount']\n",
    "\n",
    "# skew_features = all_data[columns].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "# high_skew = skew_features[abs(skew_features) > 0.75]\n",
    "# skew_index = high_skew.index\n",
    "for i in columns:\n",
    "    all_data[i] = np.log1p(all_data[i])\n",
    "# numerical_cols = []\n",
    "for c in columns:\n",
    "    prep = StandardScaler()\n",
    "    all_data[c] = prep.fit_transform(all_data[[c]])\n",
    "    # train[c] = prep.fit_transform(train[[c]])\n",
    "    # test[c] = prep.transform(test[[c]])\n",
    "    \n",
    "train = all_data[:-180581]\n",
    "test = all_data[-180581:]\n",
    "\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "y = train[['label']].values\n",
    "X = train.drop(['label'],axis=1).values\n",
    "df_test = test.drop(['label'],axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea701ea-f0e6-4548-987b-5229b9f41272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_dim,output_dim,noise=0.01):\n",
    "    i = tf.keras.layers.Input(input_dim)\n",
    "    encoded = tf.keras.layers.BatchNormalization()(i)\n",
    "    encoded = tf.keras.layers.GaussianNoise(noise)(encoded)\n",
    "    encoded = tf.keras.layers.Dense(64,activation='relu')(encoded)\n",
    "    decoded = tf.keras.layers.Dropout(0.1)(encoded)\n",
    "    decoded = tf.keras.layers.Dense(input_dim,name='decoded')(decoded)\n",
    "    x = tf.keras.layers.Dense(32,activation='relu')(decoded)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(output_dim,activation='linear',name='label_output')(x)\n",
    "    \n",
    "    encoder = tf.keras.models.Model(inputs=i,outputs=encoded)\n",
    "    autoencoder = tf.keras.models.Model(inputs=i,outputs=[decoded,x])\n",
    "    \n",
    "    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "                        loss={'decoded':'mae','label_output':'mae'})\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b40b76-0e90-47c2-97ba-f2f455b2870c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "def create_model(input_dim, output_dim, encoder):\n",
    "    # input\n",
    "    inputs = tf.keras.layers.Input(input_dim)\n",
    "    \n",
    "    x = encoder(inputs)\n",
    "    x = tf.keras.layers.Concatenate()([x,inputs]) #use both raw and encoded features\n",
    "    \n",
    "    # normalize\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # 1dcnn\n",
    "    x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = tf.keras.layers.Reshape((256, 16))(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=16,\n",
    "                      kernel_size=7,\n",
    "                      strides=1,\n",
    "                      activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    # ffn\n",
    "    for i in range(2):\n",
    "        x = tf.keras.layers.Dense(256 // (2 ** i), activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(output_dim, activation='relu')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=x)\n",
    "    \n",
    "    # compile\n",
    "    opt = tfa.optimizers.RectifiedAdam(learning_rate=1e-03)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    loss = tf.keras.losses.MeanAbsoluteError()\n",
    "    # loss = root_mean_squared_error\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=loss, \n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError(name = 'root_mean_squared_error')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66d8e6c-0f77-4e98-9e7e-b7e4a2f5dfd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 12:57:38.044890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-04 12:57:38.665922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22279 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1a:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 12:57:45.471454: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1780] (One-time warning): Not using XLA:CPU for cluster.\n",
      "\n",
      "If you want XLA:CPU, do one of the following:\n",
      "\n",
      " - set the TF_XLA_FLAGS to include \"--tf_xla_cpu_global_jit\", or\n",
      " - set cpu_global_jit to true on this session's OptimizerOptions, or\n",
      " - use experimental_jit_scope, or\n",
      " - use tf.function(jit_compile=True).\n",
      "\n",
      "To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a\n",
      "proper command-line flag, not via TF_XLA_FLAGS).\n",
      "2023-06-04 12:57:46.643460: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0xbb32b7b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-04 12:57:46.643538: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-06-04 12:57:46.662848: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-04 12:57:46.767487: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-04 12:57:46.847748: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-06-04 12:57:48.109843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075/1075 [==============================] - 20s 15ms/step - loss: 2.2772 - decoded_loss: 0.1493 - label_output_loss: 2.1279 - val_loss: 1.8811 - val_decoded_loss: 0.0949 - val_label_output_loss: 1.7862\n",
      "Epoch 2/1000\n",
      "1075/1075 [==============================] - 8s 7ms/step - loss: 1.2006 - decoded_loss: 0.0867 - label_output_loss: 1.1139 - val_loss: 1.7024 - val_decoded_loss: 0.0723 - val_label_output_loss: 1.6301\n",
      "Epoch 3/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 1.1099 - decoded_loss: 0.0734 - label_output_loss: 1.0365 - val_loss: 1.8924 - val_decoded_loss: 0.0675 - val_label_output_loss: 1.8249\n",
      "Epoch 4/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 1.0618 - decoded_loss: 0.0697 - label_output_loss: 0.9921 - val_loss: 1.8861 - val_decoded_loss: 0.0660 - val_label_output_loss: 1.8200\n",
      "Epoch 5/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 1.0282 - decoded_loss: 0.0678 - label_output_loss: 0.9604 - val_loss: 1.9392 - val_decoded_loss: 0.0635 - val_label_output_loss: 1.8756\n",
      "Epoch 6/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 1.0034 - decoded_loss: 0.0677 - label_output_loss: 0.9356 - val_loss: 1.8790 - val_decoded_loss: 0.0647 - val_label_output_loss: 1.8143\n",
      "Epoch 7/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 0.9802 - decoded_loss: 0.0660 - label_output_loss: 0.9142 - val_loss: 1.7941 - val_decoded_loss: 0.0637 - val_label_output_loss: 1.7304\n",
      "Epoch 8/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 0.9612 - decoded_loss: 0.0654 - label_output_loss: 0.8958 - val_loss: 2.0084 - val_decoded_loss: 0.0625 - val_label_output_loss: 1.9459\n",
      "Epoch 9/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 0.9491 - decoded_loss: 0.0649 - label_output_loss: 0.8842 - val_loss: 1.9148 - val_decoded_loss: 0.0636 - val_label_output_loss: 1.8513\n",
      "Epoch 10/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 0.9397 - decoded_loss: 0.0650 - label_output_loss: 0.8747 - val_loss: 1.9156 - val_decoded_loss: 0.0628 - val_label_output_loss: 1.8528\n",
      "Epoch 11/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 0.9294 - decoded_loss: 0.0649 - label_output_loss: 0.8645 - val_loss: 1.7460 - val_decoded_loss: 0.0630 - val_label_output_loss: 1.6830\n",
      "Epoch 12/1000\n",
      "1075/1075 [==============================] - 7s 6ms/step - loss: 0.9229 - decoded_loss: 0.0649 - label_output_loss: 0.8580 - val_loss: 1.9477 - val_decoded_loss: 0.0627 - val_label_output_loss: 1.8850\n"
     ]
    }
   ],
   "source": [
    "autoencoder, encoder = create_autoencoder(X.shape[-1],y.shape[-1],noise=0.1)\n",
    "autoencoder.fit(X,(X,y),\n",
    "                epochs=1000,\n",
    "                batch_size=256, \n",
    "                validation_split=0.1,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "# autoencoder.predict\n",
    "encoder.save_weights('./encoder.hdf5')\n",
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bd059ce-4176-43f1-b999-f76cea9b9e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "120/120 [==============================] - 8s 29ms/step - loss: 3.4140 - root_mean_squared_error: 3.4140 - val_loss: 2.2752 - val_root_mean_squared_error: 2.2752 - lr: 0.0010\n",
      "Epoch 2/192\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 2.1518 - root_mean_squared_error: 2.1518 - val_loss: 1.9424 - val_root_mean_squared_error: 1.9424 - lr: 0.0010\n",
      "Epoch 3/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.8133 - root_mean_squared_error: 1.8133 - val_loss: 2.1170 - val_root_mean_squared_error: 2.1170 - lr: 0.0010\n",
      "Epoch 4/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.5780 - root_mean_squared_error: 1.5780 - val_loss: 1.8669 - val_root_mean_squared_error: 1.8669 - lr: 0.0010\n",
      "Epoch 5/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 1.3985 - root_mean_squared_error: 1.3985 - val_loss: 1.4180 - val_root_mean_squared_error: 1.4180 - lr: 0.0010\n",
      "Epoch 6/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.2607 - root_mean_squared_error: 1.2607 - val_loss: 1.1869 - val_root_mean_squared_error: 1.1869 - lr: 0.0010\n",
      "Epoch 7/192\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 1.1615 - root_mean_squared_error: 1.1615 - val_loss: 1.1281 - val_root_mean_squared_error: 1.1281 - lr: 0.0010\n",
      "Epoch 8/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 1.0906 - root_mean_squared_error: 1.0906 - val_loss: 1.0243 - val_root_mean_squared_error: 1.0243 - lr: 0.0010\n",
      "Epoch 9/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.0270 - root_mean_squared_error: 1.0270 - val_loss: 0.9740 - val_root_mean_squared_error: 0.9740 - lr: 0.0010\n",
      "Epoch 10/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.9803 - root_mean_squared_error: 0.9803 - val_loss: 0.9120 - val_root_mean_squared_error: 0.9120 - lr: 0.0010\n",
      "Epoch 11/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.9378 - root_mean_squared_error: 0.9378 - val_loss: 0.8910 - val_root_mean_squared_error: 0.8910 - lr: 0.0010\n",
      "Epoch 12/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.8935 - root_mean_squared_error: 0.8935 - val_loss: 0.8890 - val_root_mean_squared_error: 0.8890 - lr: 0.0010\n",
      "Epoch 13/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.8682 - root_mean_squared_error: 0.8682 - val_loss: 0.8789 - val_root_mean_squared_error: 0.8789 - lr: 0.0010\n",
      "Epoch 14/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.8382 - root_mean_squared_error: 0.8382 - val_loss: 0.8391 - val_root_mean_squared_error: 0.8391 - lr: 0.0010\n",
      "Epoch 15/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8261 - root_mean_squared_error: 0.8261 - val_loss: 0.8229 - val_root_mean_squared_error: 0.8229 - lr: 0.0010\n",
      "Epoch 16/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.7989 - root_mean_squared_error: 0.7989 - val_loss: 0.8084 - val_root_mean_squared_error: 0.8084 - lr: 0.0010\n",
      "Epoch 17/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7874 - root_mean_squared_error: 0.7874 - val_loss: 0.7953 - val_root_mean_squared_error: 0.7953 - lr: 0.0010\n",
      "Epoch 18/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7670 - root_mean_squared_error: 0.7670 - val_loss: 0.8242 - val_root_mean_squared_error: 0.8242 - lr: 0.0010\n",
      "Epoch 19/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7511 - root_mean_squared_error: 0.7511 - val_loss: 0.7703 - val_root_mean_squared_error: 0.7703 - lr: 0.0010\n",
      "Epoch 20/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7288 - root_mean_squared_error: 0.7288 - val_loss: 0.7533 - val_root_mean_squared_error: 0.7533 - lr: 0.0010\n",
      "Epoch 21/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7151 - root_mean_squared_error: 0.7151 - val_loss: 0.7562 - val_root_mean_squared_error: 0.7562 - lr: 0.0010\n",
      "Epoch 22/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7063 - root_mean_squared_error: 0.7063 - val_loss: 0.7444 - val_root_mean_squared_error: 0.7444 - lr: 0.0010\n",
      "Epoch 23/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6880 - root_mean_squared_error: 0.6880 - val_loss: 0.7476 - val_root_mean_squared_error: 0.7476 - lr: 0.0010\n",
      "Epoch 24/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6780 - root_mean_squared_error: 0.6780 - val_loss: 0.7249 - val_root_mean_squared_error: 0.7249 - lr: 0.0010\n",
      "Epoch 25/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.6586 - root_mean_squared_error: 0.6586 - val_loss: 0.7239 - val_root_mean_squared_error: 0.7239 - lr: 0.0010\n",
      "Epoch 26/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6424 - root_mean_squared_error: 0.6424 - val_loss: 0.7218 - val_root_mean_squared_error: 0.7218 - lr: 0.0010\n",
      "Epoch 27/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.6295 - root_mean_squared_error: 0.6295 - val_loss: 0.7056 - val_root_mean_squared_error: 0.7056 - lr: 0.0010\n",
      "Epoch 28/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6168 - root_mean_squared_error: 0.6168 - val_loss: 0.6958 - val_root_mean_squared_error: 0.6958 - lr: 0.0010\n",
      "Epoch 29/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.6035 - root_mean_squared_error: 0.6035 - val_loss: 0.6908 - val_root_mean_squared_error: 0.6908 - lr: 0.0010\n",
      "Epoch 30/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5982 - root_mean_squared_error: 0.5982 - val_loss: 0.6976 - val_root_mean_squared_error: 0.6976 - lr: 0.0010\n",
      "Epoch 31/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.5867 - root_mean_squared_error: 0.5867 - val_loss: 0.6818 - val_root_mean_squared_error: 0.6818 - lr: 0.0010\n",
      "Epoch 32/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5787 - root_mean_squared_error: 0.5787 - val_loss: 0.6908 - val_root_mean_squared_error: 0.6908 - lr: 0.0010\n",
      "Epoch 33/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.5776 - root_mean_squared_error: 0.5776 - val_loss: 0.6844 - val_root_mean_squared_error: 0.6844 - lr: 0.0010\n",
      "Epoch 34/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5645 - root_mean_squared_error: 0.5645 - val_loss: 0.6661 - val_root_mean_squared_error: 0.6661 - lr: 0.0010\n",
      "Epoch 35/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5447 - root_mean_squared_error: 0.5447 - val_loss: 0.6586 - val_root_mean_squared_error: 0.6586 - lr: 0.0010\n",
      "Epoch 36/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5313 - root_mean_squared_error: 0.5313 - val_loss: 0.6521 - val_root_mean_squared_error: 0.6521 - lr: 0.0010\n",
      "Epoch 37/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5239 - root_mean_squared_error: 0.5239 - val_loss: 0.6496 - val_root_mean_squared_error: 0.6496 - lr: 0.0010\n",
      "Epoch 38/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.5203 - root_mean_squared_error: 0.5203 - val_loss: 0.6525 - val_root_mean_squared_error: 0.6525 - lr: 0.0010\n",
      "Epoch 39/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5145 - root_mean_squared_error: 0.5145 - val_loss: 0.6393 - val_root_mean_squared_error: 0.6393 - lr: 0.0010\n",
      "Epoch 40/192\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.5048 - root_mean_squared_error: 0.5048 - val_loss: 0.6363 - val_root_mean_squared_error: 0.6363 - lr: 0.0010\n",
      "Epoch 41/192\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.5022 - root_mean_squared_error: 0.5022 - val_loss: 0.6441 - val_root_mean_squared_error: 0.6441 - lr: 0.0010\n",
      "Epoch 42/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4975 - root_mean_squared_error: 0.4975 - val_loss: 0.6422 - val_root_mean_squared_error: 0.6422 - lr: 0.0010\n",
      "Epoch 43/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4944 - root_mean_squared_error: 0.4944 - val_loss: 0.6459 - val_root_mean_squared_error: 0.6459 - lr: 0.0010\n",
      "Epoch 44/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4908 - root_mean_squared_error: 0.4908 - val_loss: 0.6567 - val_root_mean_squared_error: 0.6567 - lr: 0.0010\n",
      "Epoch 45/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.4879 - root_mean_squared_error: 0.4879 - val_loss: 0.6341 - val_root_mean_squared_error: 0.6341 - lr: 0.0010\n",
      "Epoch 46/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4818 - root_mean_squared_error: 0.4818 - val_loss: 0.6358 - val_root_mean_squared_error: 0.6358 - lr: 0.0010\n",
      "Epoch 47/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4812 - root_mean_squared_error: 0.4812 - val_loss: 0.6366 - val_root_mean_squared_error: 0.6366 - lr: 0.0010\n",
      "Epoch 48/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4801 - root_mean_squared_error: 0.4801 - val_loss: 0.6313 - val_root_mean_squared_error: 0.6313 - lr: 0.0010\n",
      "Epoch 49/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4774 - root_mean_squared_error: 0.4774 - val_loss: 0.6322 - val_root_mean_squared_error: 0.6322 - lr: 0.0010\n",
      "Epoch 50/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4723 - root_mean_squared_error: 0.4723 - val_loss: 0.6314 - val_root_mean_squared_error: 0.6314 - lr: 0.0010\n",
      "Epoch 51/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4718 - root_mean_squared_error: 0.4718 - val_loss: 0.6325 - val_root_mean_squared_error: 0.6325 - lr: 0.0010\n",
      "Epoch 52/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4667 - root_mean_squared_error: 0.4667 - val_loss: 0.6257 - val_root_mean_squared_error: 0.6257 - lr: 0.0010\n",
      "Epoch 53/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4653 - root_mean_squared_error: 0.4653 - val_loss: 0.6342 - val_root_mean_squared_error: 0.6342 - lr: 0.0010\n",
      "Epoch 54/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4677 - root_mean_squared_error: 0.4677 - val_loss: 0.6252 - val_root_mean_squared_error: 0.6252 - lr: 0.0010\n",
      "Epoch 55/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4629 - root_mean_squared_error: 0.4629 - val_loss: 0.6287 - val_root_mean_squared_error: 0.6287 - lr: 0.0010\n",
      "Epoch 56/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4595 - root_mean_squared_error: 0.4595 - val_loss: 0.6290 - val_root_mean_squared_error: 0.6290 - lr: 0.0010\n",
      "Epoch 57/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4567 - root_mean_squared_error: 0.4567 - val_loss: 0.6246 - val_root_mean_squared_error: 0.6246 - lr: 0.0010\n",
      "Epoch 58/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4555 - root_mean_squared_error: 0.4555 - val_loss: 0.6253 - val_root_mean_squared_error: 0.6253 - lr: 0.0010\n",
      "Epoch 59/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4526 - root_mean_squared_error: 0.4526 - val_loss: 0.6293 - val_root_mean_squared_error: 0.6293 - lr: 0.0010\n",
      "Epoch 60/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4535 - root_mean_squared_error: 0.4535 - val_loss: 0.6249 - val_root_mean_squared_error: 0.6249 - lr: 0.0010\n",
      "Epoch 61/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4489 - root_mean_squared_error: 0.4489 - val_loss: 0.6189 - val_root_mean_squared_error: 0.6189 - lr: 0.0010\n",
      "Epoch 62/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4470 - root_mean_squared_error: 0.4470 - val_loss: 0.6235 - val_root_mean_squared_error: 0.6235 - lr: 0.0010\n",
      "Epoch 63/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4468 - root_mean_squared_error: 0.4468 - val_loss: 0.6197 - val_root_mean_squared_error: 0.6197 - lr: 0.0010\n",
      "Epoch 64/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4444 - root_mean_squared_error: 0.4444 - val_loss: 0.6186 - val_root_mean_squared_error: 0.6186 - lr: 0.0010\n",
      "Epoch 65/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4444 - root_mean_squared_error: 0.4444 - val_loss: 0.6299 - val_root_mean_squared_error: 0.6299 - lr: 0.0010\n",
      "Epoch 66/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4424 - root_mean_squared_error: 0.4424 - val_loss: 0.6253 - val_root_mean_squared_error: 0.6253 - lr: 0.0010\n",
      "Epoch 67/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4390 - root_mean_squared_error: 0.4390 - val_loss: 0.6299 - val_root_mean_squared_error: 0.6299 - lr: 0.0010\n",
      "Epoch 68/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4370 - root_mean_squared_error: 0.4370 - val_loss: 0.6167 - val_root_mean_squared_error: 0.6167 - lr: 0.0010\n",
      "Epoch 69/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4350 - root_mean_squared_error: 0.4350 - val_loss: 0.6241 - val_root_mean_squared_error: 0.6241 - lr: 0.0010\n",
      "Epoch 70/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4351 - root_mean_squared_error: 0.4351 - val_loss: 0.6270 - val_root_mean_squared_error: 0.6270 - lr: 0.0010\n",
      "Epoch 71/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4329 - root_mean_squared_error: 0.4329 - val_loss: 0.6233 - val_root_mean_squared_error: 0.6233 - lr: 0.0010\n",
      "Epoch 72/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4315 - root_mean_squared_error: 0.4315 - val_loss: 0.6168 - val_root_mean_squared_error: 0.6168 - lr: 0.0010\n",
      "Epoch 73/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4289 - root_mean_squared_error: 0.4289 - val_loss: 0.6231 - val_root_mean_squared_error: 0.6231 - lr: 0.0010\n",
      "Epoch 74/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4287 - root_mean_squared_error: 0.4287 - val_loss: 0.6252 - val_root_mean_squared_error: 0.6252 - lr: 0.0010\n",
      "Epoch 75/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4275 - root_mean_squared_error: 0.4275 - val_loss: 0.6164 - val_root_mean_squared_error: 0.6164 - lr: 0.0010\n",
      "Epoch 76/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.4255 - root_mean_squared_error: 0.4255 - val_loss: 0.6146 - val_root_mean_squared_error: 0.6146 - lr: 0.0010\n",
      "Epoch 77/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4232 - root_mean_squared_error: 0.4232 - val_loss: 0.6160 - val_root_mean_squared_error: 0.6160 - lr: 0.0010\n",
      "Epoch 78/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4241 - root_mean_squared_error: 0.4241 - val_loss: 0.6146 - val_root_mean_squared_error: 0.6146 - lr: 0.0010\n",
      "Epoch 79/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4206 - root_mean_squared_error: 0.4206 - val_loss: 0.6194 - val_root_mean_squared_error: 0.6194 - lr: 0.0010\n",
      "Epoch 80/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4181 - root_mean_squared_error: 0.4181 - val_loss: 0.6181 - val_root_mean_squared_error: 0.6181 - lr: 0.0010\n",
      "Epoch 81/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4178 - root_mean_squared_error: 0.4178 - val_loss: 0.6126 - val_root_mean_squared_error: 0.6126 - lr: 0.0010\n",
      "Epoch 82/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4169 - root_mean_squared_error: 0.4169 - val_loss: 0.6202 - val_root_mean_squared_error: 0.6202 - lr: 0.0010\n",
      "Epoch 83/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4192 - root_mean_squared_error: 0.4192 - val_loss: 0.6123 - val_root_mean_squared_error: 0.6123 - lr: 0.0010\n",
      "Epoch 84/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4116 - root_mean_squared_error: 0.4116 - val_loss: 0.6113 - val_root_mean_squared_error: 0.6113 - lr: 0.0010\n",
      "Epoch 85/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4124 - root_mean_squared_error: 0.4124 - val_loss: 0.6178 - val_root_mean_squared_error: 0.6178 - lr: 0.0010\n",
      "Epoch 86/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4104 - root_mean_squared_error: 0.4104 - val_loss: 0.6138 - val_root_mean_squared_error: 0.6138 - lr: 0.0010\n",
      "Epoch 87/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4075 - root_mean_squared_error: 0.4075 - val_loss: 0.6140 - val_root_mean_squared_error: 0.6140 - lr: 0.0010\n",
      "Epoch 88/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4080 - root_mean_squared_error: 0.4080 - val_loss: 0.6116 - val_root_mean_squared_error: 0.6116 - lr: 0.0010\n",
      "Epoch 89/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.4045 - root_mean_squared_error: 0.4045 - val_loss: 0.6136 - val_root_mean_squared_error: 0.6136 - lr: 0.0010\n",
      "Epoch 90/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4091 - root_mean_squared_error: 0.4091 - val_loss: 0.6127 - val_root_mean_squared_error: 0.6127 - lr: 0.0010\n",
      "Epoch 91/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4054 - root_mean_squared_error: 0.4054 - val_loss: 0.6147 - val_root_mean_squared_error: 0.6147 - lr: 0.0010\n",
      "Epoch 92/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4036 - root_mean_squared_error: 0.4036 - val_loss: 0.6083 - val_root_mean_squared_error: 0.6083 - lr: 0.0010\n",
      "Epoch 93/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4012 - root_mean_squared_error: 0.4012 - val_loss: 0.6088 - val_root_mean_squared_error: 0.6088 - lr: 0.0010\n",
      "Epoch 94/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3996 - root_mean_squared_error: 0.3996 - val_loss: 0.6111 - val_root_mean_squared_error: 0.6111 - lr: 0.0010\n",
      "Epoch 95/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.3987 - root_mean_squared_error: 0.3987 - val_loss: 0.6209 - val_root_mean_squared_error: 0.6209 - lr: 0.0010\n",
      "Epoch 96/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3967 - root_mean_squared_error: 0.3967 - val_loss: 0.6060 - val_root_mean_squared_error: 0.6060 - lr: 0.0010\n",
      "Epoch 97/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4002 - root_mean_squared_error: 0.4002 - val_loss: 0.6098 - val_root_mean_squared_error: 0.6098 - lr: 0.0010\n",
      "Epoch 98/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4008 - root_mean_squared_error: 0.4008 - val_loss: 0.6061 - val_root_mean_squared_error: 0.6061 - lr: 0.0010\n",
      "Epoch 99/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3970 - root_mean_squared_error: 0.3970 - val_loss: 0.6085 - val_root_mean_squared_error: 0.6085 - lr: 0.0010\n",
      "Epoch 100/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3962 - root_mean_squared_error: 0.3962 - val_loss: 0.6126 - val_root_mean_squared_error: 0.6126 - lr: 0.0010\n",
      "Epoch 101/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3942 - root_mean_squared_error: 0.3942 - val_loss: 0.6111 - val_root_mean_squared_error: 0.6111 - lr: 0.0010\n",
      "Epoch 102/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3912 - root_mean_squared_error: 0.3912 - val_loss: 0.6160 - val_root_mean_squared_error: 0.6160 - lr: 0.0010\n",
      "Epoch 103/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3933 - root_mean_squared_error: 0.3933 - val_loss: 0.6054 - val_root_mean_squared_error: 0.6054 - lr: 0.0010\n",
      "Epoch 104/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3883 - root_mean_squared_error: 0.3883 - val_loss: 0.6065 - val_root_mean_squared_error: 0.6065 - lr: 0.0010\n",
      "Epoch 105/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3882 - root_mean_squared_error: 0.3882 - val_loss: 0.6069 - val_root_mean_squared_error: 0.6069 - lr: 0.0010\n",
      "Epoch 106/192\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.3882 - root_mean_squared_error: 0.3882 - val_loss: 0.6154 - val_root_mean_squared_error: 0.6154 - lr: 0.0010\n",
      "Epoch 107/192\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.3867 - root_mean_squared_error: 0.3867 - val_loss: 0.6038 - val_root_mean_squared_error: 0.6038 - lr: 0.0010\n",
      "Epoch 108/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3863 - root_mean_squared_error: 0.3863 - val_loss: 0.6077 - val_root_mean_squared_error: 0.6077 - lr: 0.0010\n",
      "Epoch 109/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3839 - root_mean_squared_error: 0.3839 - val_loss: 0.6047 - val_root_mean_squared_error: 0.6047 - lr: 0.0010\n",
      "Epoch 110/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3793 - root_mean_squared_error: 0.3793 - val_loss: 0.6036 - val_root_mean_squared_error: 0.6036 - lr: 0.0010\n",
      "Epoch 111/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3813 - root_mean_squared_error: 0.3813 - val_loss: 0.5999 - val_root_mean_squared_error: 0.5999 - lr: 0.0010\n",
      "Epoch 112/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3775 - root_mean_squared_error: 0.3775 - val_loss: 0.5993 - val_root_mean_squared_error: 0.5993 - lr: 0.0010\n",
      "Epoch 113/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3760 - root_mean_squared_error: 0.3760 - val_loss: 0.5966 - val_root_mean_squared_error: 0.5966 - lr: 0.0010\n",
      "Epoch 114/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3733 - root_mean_squared_error: 0.3733 - val_loss: 0.5951 - val_root_mean_squared_error: 0.5951 - lr: 0.0010\n",
      "Epoch 115/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.3718 - root_mean_squared_error: 0.3718 - val_loss: 0.5966 - val_root_mean_squared_error: 0.5966 - lr: 0.0010\n",
      "Epoch 116/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3705 - root_mean_squared_error: 0.3705 - val_loss: 0.5983 - val_root_mean_squared_error: 0.5983 - lr: 0.0010\n",
      "Epoch 117/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3713 - root_mean_squared_error: 0.3713 - val_loss: 0.6041 - val_root_mean_squared_error: 0.6041 - lr: 0.0010\n",
      "Epoch 118/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3687 - root_mean_squared_error: 0.3687 - val_loss: 0.5942 - val_root_mean_squared_error: 0.5942 - lr: 0.0010\n",
      "Epoch 119/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3677 - root_mean_squared_error: 0.3677 - val_loss: 0.5974 - val_root_mean_squared_error: 0.5974 - lr: 0.0010\n",
      "Epoch 120/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3666 - root_mean_squared_error: 0.3666 - val_loss: 0.5929 - val_root_mean_squared_error: 0.5929 - lr: 0.0010\n",
      "Epoch 121/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3680 - root_mean_squared_error: 0.3680 - val_loss: 0.5973 - val_root_mean_squared_error: 0.5973 - lr: 0.0010\n",
      "Epoch 122/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.3649 - root_mean_squared_error: 0.3649 - val_loss: 0.5945 - val_root_mean_squared_error: 0.5945 - lr: 0.0010\n",
      "Epoch 123/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.3638 - root_mean_squared_error: 0.3638 - val_loss: 0.5890 - val_root_mean_squared_error: 0.5890 - lr: 0.0010\n",
      "Epoch 124/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3616 - root_mean_squared_error: 0.3616 - val_loss: 0.5921 - val_root_mean_squared_error: 0.5921 - lr: 0.0010\n",
      "Epoch 125/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3585 - root_mean_squared_error: 0.3585 - val_loss: 0.5921 - val_root_mean_squared_error: 0.5921 - lr: 0.0010\n",
      "Epoch 126/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3572 - root_mean_squared_error: 0.3572 - val_loss: 0.5958 - val_root_mean_squared_error: 0.5958 - lr: 0.0010\n",
      "Epoch 127/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.3570 - root_mean_squared_error: 0.3570 - val_loss: 0.5934 - val_root_mean_squared_error: 0.5934 - lr: 0.0010\n",
      "Epoch 128/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3549 - root_mean_squared_error: 0.3549 - val_loss: 0.5959 - val_root_mean_squared_error: 0.5959 - lr: 0.0010\n",
      "Epoch 129/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3553 - root_mean_squared_error: 0.3553 - val_loss: 0.5929 - val_root_mean_squared_error: 0.5929 - lr: 0.0010\n",
      "Epoch 130/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3530 - root_mean_squared_error: 0.3530 - val_loss: 0.5908 - val_root_mean_squared_error: 0.5908 - lr: 0.0010\n",
      "Epoch 131/192\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.3534 - root_mean_squared_error: 0.3534\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.3536 - root_mean_squared_error: 0.3536 - val_loss: 0.5933 - val_root_mean_squared_error: 0.5933 - lr: 0.0010\n",
      "5644/5644 [==============================] - 11s 2ms/step\n",
      "Epoch 1/192\n",
      "120/120 [==============================] - 8s 29ms/step - loss: 3.6010 - root_mean_squared_error: 3.6010 - val_loss: 4.2820 - val_root_mean_squared_error: 4.2820 - lr: 0.0010\n",
      "Epoch 2/192\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 2.0348 - root_mean_squared_error: 2.0348 - val_loss: 2.5955 - val_root_mean_squared_error: 2.5955 - lr: 0.0010\n",
      "Epoch 3/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 1.7057 - root_mean_squared_error: 1.7057 - val_loss: 1.5705 - val_root_mean_squared_error: 1.5705 - lr: 0.0010\n",
      "Epoch 4/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 1.4858 - root_mean_squared_error: 1.4858 - val_loss: 1.3556 - val_root_mean_squared_error: 1.3556 - lr: 0.0010\n",
      "Epoch 5/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.3320 - root_mean_squared_error: 1.3320 - val_loss: 1.3146 - val_root_mean_squared_error: 1.3146 - lr: 0.0010\n",
      "Epoch 6/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.2254 - root_mean_squared_error: 1.2254 - val_loss: 1.1929 - val_root_mean_squared_error: 1.1929 - lr: 0.0010\n",
      "Epoch 7/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.1384 - root_mean_squared_error: 1.1384 - val_loss: 1.0548 - val_root_mean_squared_error: 1.0548 - lr: 0.0010\n",
      "Epoch 8/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.0579 - root_mean_squared_error: 1.0579 - val_loss: 1.0150 - val_root_mean_squared_error: 1.0150 - lr: 0.0010\n",
      "Epoch 9/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.0201 - root_mean_squared_error: 1.0201 - val_loss: 0.9965 - val_root_mean_squared_error: 0.9965 - lr: 0.0010\n",
      "Epoch 10/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.9808 - root_mean_squared_error: 0.9808 - val_loss: 0.9528 - val_root_mean_squared_error: 0.9528 - lr: 0.0010\n",
      "Epoch 11/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.9590 - root_mean_squared_error: 0.9590 - val_loss: 0.9316 - val_root_mean_squared_error: 0.9316 - lr: 0.0010\n",
      "Epoch 12/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.9243 - root_mean_squared_error: 0.9243 - val_loss: 0.9020 - val_root_mean_squared_error: 0.9020 - lr: 0.0010\n",
      "Epoch 13/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8964 - root_mean_squared_error: 0.8964 - val_loss: 0.9027 - val_root_mean_squared_error: 0.9027 - lr: 0.0010\n",
      "Epoch 14/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8621 - root_mean_squared_error: 0.8621 - val_loss: 0.8535 - val_root_mean_squared_error: 0.8535 - lr: 0.0010\n",
      "Epoch 15/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8381 - root_mean_squared_error: 0.8381 - val_loss: 0.8396 - val_root_mean_squared_error: 0.8396 - lr: 0.0010\n",
      "Epoch 16/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8199 - root_mean_squared_error: 0.8199 - val_loss: 0.8180 - val_root_mean_squared_error: 0.8180 - lr: 0.0010\n",
      "Epoch 17/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.7993 - root_mean_squared_error: 0.7993 - val_loss: 0.7954 - val_root_mean_squared_error: 0.7954 - lr: 0.0010\n",
      "Epoch 18/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7757 - root_mean_squared_error: 0.7757 - val_loss: 0.7902 - val_root_mean_squared_error: 0.7902 - lr: 0.0010\n",
      "Epoch 19/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7653 - root_mean_squared_error: 0.7653 - val_loss: 0.7867 - val_root_mean_squared_error: 0.7867 - lr: 0.0010\n",
      "Epoch 20/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7554 - root_mean_squared_error: 0.7554 - val_loss: 0.7836 - val_root_mean_squared_error: 0.7836 - lr: 0.0010\n",
      "Epoch 21/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7400 - root_mean_squared_error: 0.7400 - val_loss: 0.7750 - val_root_mean_squared_error: 0.7750 - lr: 0.0010\n",
      "Epoch 22/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7304 - root_mean_squared_error: 0.7304 - val_loss: 0.7719 - val_root_mean_squared_error: 0.7719 - lr: 0.0010\n",
      "Epoch 23/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7164 - root_mean_squared_error: 0.7164 - val_loss: 0.7624 - val_root_mean_squared_error: 0.7624 - lr: 0.0010\n",
      "Epoch 24/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6997 - root_mean_squared_error: 0.6997 - val_loss: 0.7773 - val_root_mean_squared_error: 0.7773 - lr: 0.0010\n",
      "Epoch 25/192\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.6888 - root_mean_squared_error: 0.6888 - val_loss: 0.7536 - val_root_mean_squared_error: 0.7536 - lr: 0.0010\n",
      "Epoch 26/192\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.6797 - root_mean_squared_error: 0.6797 - val_loss: 0.7386 - val_root_mean_squared_error: 0.7386 - lr: 0.0010\n",
      "Epoch 27/192\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.6672 - root_mean_squared_error: 0.6672 - val_loss: 0.7340 - val_root_mean_squared_error: 0.7340 - lr: 0.0010\n",
      "Epoch 28/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6614 - root_mean_squared_error: 0.6614 - val_loss: 0.7815 - val_root_mean_squared_error: 0.7815 - lr: 0.0010\n",
      "Epoch 29/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6523 - root_mean_squared_error: 0.6523 - val_loss: 0.7385 - val_root_mean_squared_error: 0.7385 - lr: 0.0010\n",
      "Epoch 30/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6444 - root_mean_squared_error: 0.6444 - val_loss: 0.7399 - val_root_mean_squared_error: 0.7399 - lr: 0.0010\n",
      "Epoch 31/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6291 - root_mean_squared_error: 0.6291 - val_loss: 0.7187 - val_root_mean_squared_error: 0.7187 - lr: 0.0010\n",
      "Epoch 32/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.6138 - root_mean_squared_error: 0.6138 - val_loss: 0.7123 - val_root_mean_squared_error: 0.7123 - lr: 0.0010\n",
      "Epoch 33/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.6031 - root_mean_squared_error: 0.6031 - val_loss: 0.7079 - val_root_mean_squared_error: 0.7079 - lr: 0.0010\n",
      "Epoch 34/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5975 - root_mean_squared_error: 0.5975 - val_loss: 0.7132 - val_root_mean_squared_error: 0.7132 - lr: 0.0010\n",
      "Epoch 35/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5800 - root_mean_squared_error: 0.5800 - val_loss: 0.7004 - val_root_mean_squared_error: 0.7004 - lr: 0.0010\n",
      "Epoch 36/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5756 - root_mean_squared_error: 0.5756 - val_loss: 0.7027 - val_root_mean_squared_error: 0.7027 - lr: 0.0010\n",
      "Epoch 37/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5675 - root_mean_squared_error: 0.5675 - val_loss: 0.6938 - val_root_mean_squared_error: 0.6938 - lr: 0.0010\n",
      "Epoch 38/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5571 - root_mean_squared_error: 0.5571 - val_loss: 0.7050 - val_root_mean_squared_error: 0.7050 - lr: 0.0010\n",
      "Epoch 39/192\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.5429 - root_mean_squared_error: 0.5429 - val_loss: 0.6766 - val_root_mean_squared_error: 0.6766 - lr: 0.0010\n",
      "Epoch 40/192\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.5323 - root_mean_squared_error: 0.5323 - val_loss: 0.6648 - val_root_mean_squared_error: 0.6648 - lr: 0.0010\n",
      "Epoch 41/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.5240 - root_mean_squared_error: 0.5240 - val_loss: 0.6656 - val_root_mean_squared_error: 0.6656 - lr: 0.0010\n",
      "Epoch 42/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5194 - root_mean_squared_error: 0.5194 - val_loss: 0.6688 - val_root_mean_squared_error: 0.6688 - lr: 0.0010\n",
      "Epoch 43/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5164 - root_mean_squared_error: 0.5164 - val_loss: 0.6818 - val_root_mean_squared_error: 0.6818 - lr: 0.0010\n",
      "Epoch 44/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.5130 - root_mean_squared_error: 0.5130 - val_loss: 0.6600 - val_root_mean_squared_error: 0.6600 - lr: 0.0010\n",
      "Epoch 45/192\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.5091 - root_mean_squared_error: 0.5091 - val_loss: 0.6603 - val_root_mean_squared_error: 0.6603 - lr: 0.0010\n",
      "Epoch 46/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5038 - root_mean_squared_error: 0.5038 - val_loss: 0.6707 - val_root_mean_squared_error: 0.6707 - lr: 0.0010\n",
      "Epoch 47/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4903 - root_mean_squared_error: 0.4903 - val_loss: 0.6532 - val_root_mean_squared_error: 0.6532 - lr: 0.0010\n",
      "Epoch 48/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4828 - root_mean_squared_error: 0.4828 - val_loss: 0.6362 - val_root_mean_squared_error: 0.6362 - lr: 0.0010\n",
      "Epoch 49/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4794 - root_mean_squared_error: 0.4794 - val_loss: 0.6324 - val_root_mean_squared_error: 0.6324 - lr: 0.0010\n",
      "Epoch 50/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4720 - root_mean_squared_error: 0.4720 - val_loss: 0.6303 - val_root_mean_squared_error: 0.6303 - lr: 0.0010\n",
      "Epoch 51/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4728 - root_mean_squared_error: 0.4728 - val_loss: 0.6314 - val_root_mean_squared_error: 0.6314 - lr: 0.0010\n",
      "Epoch 52/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.4686 - root_mean_squared_error: 0.4686 - val_loss: 0.6288 - val_root_mean_squared_error: 0.6288 - lr: 0.0010\n",
      "Epoch 53/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4658 - root_mean_squared_error: 0.4658 - val_loss: 0.6318 - val_root_mean_squared_error: 0.6318 - lr: 0.0010\n",
      "Epoch 54/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4636 - root_mean_squared_error: 0.4636 - val_loss: 0.6240 - val_root_mean_squared_error: 0.6240 - lr: 0.0010\n",
      "Epoch 55/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4617 - root_mean_squared_error: 0.4617 - val_loss: 0.6262 - val_root_mean_squared_error: 0.6262 - lr: 0.0010\n",
      "Epoch 56/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4604 - root_mean_squared_error: 0.4604 - val_loss: 0.6293 - val_root_mean_squared_error: 0.6293 - lr: 0.0010\n",
      "Epoch 57/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4622 - root_mean_squared_error: 0.4622 - val_loss: 0.6312 - val_root_mean_squared_error: 0.6312 - lr: 0.0010\n",
      "Epoch 58/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4572 - root_mean_squared_error: 0.4572 - val_loss: 0.6250 - val_root_mean_squared_error: 0.6250 - lr: 0.0010\n",
      "Epoch 59/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4538 - root_mean_squared_error: 0.4538 - val_loss: 0.6338 - val_root_mean_squared_error: 0.6338 - lr: 0.0010\n",
      "Epoch 60/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4533 - root_mean_squared_error: 0.4533 - val_loss: 0.8905 - val_root_mean_squared_error: 0.8905 - lr: 0.0010\n",
      "Epoch 61/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.4515 - root_mean_squared_error: 0.4515 - val_loss: 0.6213 - val_root_mean_squared_error: 0.6213 - lr: 0.0010\n",
      "Epoch 62/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4446 - root_mean_squared_error: 0.4446 - val_loss: 0.6235 - val_root_mean_squared_error: 0.6235 - lr: 0.0010\n",
      "Epoch 63/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4437 - root_mean_squared_error: 0.4437 - val_loss: 0.6274 - val_root_mean_squared_error: 0.6274 - lr: 0.0010\n",
      "Epoch 64/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4440 - root_mean_squared_error: 0.4440 - val_loss: 0.6160 - val_root_mean_squared_error: 0.6160 - lr: 0.0010\n",
      "Epoch 65/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4427 - root_mean_squared_error: 0.4427 - val_loss: 0.6214 - val_root_mean_squared_error: 0.6214 - lr: 0.0010\n",
      "Epoch 66/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4397 - root_mean_squared_error: 0.4397 - val_loss: 0.6212 - val_root_mean_squared_error: 0.6212 - lr: 0.0010\n",
      "Epoch 67/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4360 - root_mean_squared_error: 0.4360 - val_loss: 0.6162 - val_root_mean_squared_error: 0.6162 - lr: 0.0010\n",
      "Epoch 68/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4347 - root_mean_squared_error: 0.4347 - val_loss: 0.6219 - val_root_mean_squared_error: 0.6219 - lr: 0.0010\n",
      "Epoch 69/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4331 - root_mean_squared_error: 0.4331 - val_loss: 0.6224 - val_root_mean_squared_error: 0.6224 - lr: 0.0010\n",
      "Epoch 70/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4332 - root_mean_squared_error: 0.4332 - val_loss: 0.6163 - val_root_mean_squared_error: 0.6163 - lr: 0.0010\n",
      "Epoch 71/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4304 - root_mean_squared_error: 0.4304 - val_loss: 0.6236 - val_root_mean_squared_error: 0.6236 - lr: 0.0010\n",
      "Epoch 72/192\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4338 - root_mean_squared_error: 0.4338\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4338 - root_mean_squared_error: 0.4338 - val_loss: 0.6187 - val_root_mean_squared_error: 0.6187 - lr: 0.0010\n",
      "5644/5644 [==============================] - 11s 2ms/step\n",
      "Epoch 1/192\n",
      "120/120 [==============================] - 8s 29ms/step - loss: 3.7424 - root_mean_squared_error: 3.7424 - val_loss: 4.3407 - val_root_mean_squared_error: 4.3407 - lr: 0.0010\n",
      "Epoch 2/192\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 2.2574 - root_mean_squared_error: 2.2574 - val_loss: 2.5115 - val_root_mean_squared_error: 2.5115 - lr: 0.0010\n",
      "Epoch 3/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.9350 - root_mean_squared_error: 1.9350 - val_loss: 1.7749 - val_root_mean_squared_error: 1.7749 - lr: 0.0010\n",
      "Epoch 4/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.7367 - root_mean_squared_error: 1.7367 - val_loss: 1.6122 - val_root_mean_squared_error: 1.6122 - lr: 0.0010\n",
      "Epoch 5/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.5782 - root_mean_squared_error: 1.5782 - val_loss: 1.4685 - val_root_mean_squared_error: 1.4685 - lr: 0.0010\n",
      "Epoch 6/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 1.4679 - root_mean_squared_error: 1.4679 - val_loss: 1.3966 - val_root_mean_squared_error: 1.3966 - lr: 0.0010\n",
      "Epoch 7/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.3724 - root_mean_squared_error: 1.3724 - val_loss: 1.2859 - val_root_mean_squared_error: 1.2859 - lr: 0.0010\n",
      "Epoch 8/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 1.3036 - root_mean_squared_error: 1.3036 - val_loss: 1.2553 - val_root_mean_squared_error: 1.2553 - lr: 0.0010\n",
      "Epoch 9/192\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 1.2276 - root_mean_squared_error: 1.2276 - val_loss: 1.2057 - val_root_mean_squared_error: 1.2057 - lr: 0.0010\n",
      "Epoch 10/192\n",
      "120/120 [==============================] - 6s 49ms/step - loss: 1.1502 - root_mean_squared_error: 1.1502 - val_loss: 1.1475 - val_root_mean_squared_error: 1.1475 - lr: 0.0010\n",
      "Epoch 11/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.0907 - root_mean_squared_error: 1.0907 - val_loss: 1.0891 - val_root_mean_squared_error: 1.0891 - lr: 0.0010\n",
      "Epoch 12/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 1.0561 - root_mean_squared_error: 1.0561 - val_loss: 1.0458 - val_root_mean_squared_error: 1.0458 - lr: 0.0010\n",
      "Epoch 13/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.0142 - root_mean_squared_error: 1.0142 - val_loss: 1.0337 - val_root_mean_squared_error: 1.0337 - lr: 0.0010\n",
      "Epoch 14/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.9803 - root_mean_squared_error: 0.9803 - val_loss: 0.9908 - val_root_mean_squared_error: 0.9908 - lr: 0.0010\n",
      "Epoch 15/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.9301 - root_mean_squared_error: 0.9301 - val_loss: 0.9363 - val_root_mean_squared_error: 0.9363 - lr: 0.0010\n",
      "Epoch 16/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.8942 - root_mean_squared_error: 0.8942 - val_loss: 0.9010 - val_root_mean_squared_error: 0.9010 - lr: 0.0010\n",
      "Epoch 17/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8704 - root_mean_squared_error: 0.8704 - val_loss: 0.9085 - val_root_mean_squared_error: 0.9085 - lr: 0.0010\n",
      "Epoch 18/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8456 - root_mean_squared_error: 0.8456 - val_loss: 0.8651 - val_root_mean_squared_error: 0.8651 - lr: 0.0010\n",
      "Epoch 19/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8269 - root_mean_squared_error: 0.8269 - val_loss: 0.8679 - val_root_mean_squared_error: 0.8679 - lr: 0.0010\n",
      "Epoch 20/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8138 - root_mean_squared_error: 0.8138 - val_loss: 0.8539 - val_root_mean_squared_error: 0.8539 - lr: 0.0010\n",
      "Epoch 21/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.7944 - root_mean_squared_error: 0.7944 - val_loss: 0.8186 - val_root_mean_squared_error: 0.8186 - lr: 0.0010\n",
      "Epoch 22/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7753 - root_mean_squared_error: 0.7753 - val_loss: 0.8243 - val_root_mean_squared_error: 0.8243 - lr: 0.0010\n",
      "Epoch 23/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7584 - root_mean_squared_error: 0.7584 - val_loss: 0.8121 - val_root_mean_squared_error: 0.8121 - lr: 0.0010\n",
      "Epoch 24/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7474 - root_mean_squared_error: 0.7474 - val_loss: 0.8135 - val_root_mean_squared_error: 0.8135 - lr: 0.0010\n",
      "Epoch 25/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7290 - root_mean_squared_error: 0.7290 - val_loss: 0.7923 - val_root_mean_squared_error: 0.7923 - lr: 0.0010\n",
      "Epoch 26/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7149 - root_mean_squared_error: 0.7149 - val_loss: 0.7853 - val_root_mean_squared_error: 0.7853 - lr: 0.0010\n",
      "Epoch 27/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7019 - root_mean_squared_error: 0.7019 - val_loss: 0.7712 - val_root_mean_squared_error: 0.7712 - lr: 0.0010\n",
      "Epoch 28/192\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.6904 - root_mean_squared_error: 0.6904 - val_loss: 0.7742 - val_root_mean_squared_error: 0.7742 - lr: 0.0010\n",
      "Epoch 29/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.6718 - root_mean_squared_error: 0.6718 - val_loss: 0.7574 - val_root_mean_squared_error: 0.7574 - lr: 0.0010\n",
      "Epoch 30/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6685 - root_mean_squared_error: 0.6685 - val_loss: 0.7536 - val_root_mean_squared_error: 0.7536 - lr: 0.0010\n",
      "Epoch 31/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6550 - root_mean_squared_error: 0.6550 - val_loss: 0.7542 - val_root_mean_squared_error: 0.7542 - lr: 0.0010\n",
      "Epoch 32/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6453 - root_mean_squared_error: 0.6453 - val_loss: 0.7672 - val_root_mean_squared_error: 0.7672 - lr: 0.0010\n",
      "Epoch 33/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6337 - root_mean_squared_error: 0.6337 - val_loss: 0.7565 - val_root_mean_squared_error: 0.7565 - lr: 0.0010\n",
      "Epoch 34/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6127 - root_mean_squared_error: 0.6127 - val_loss: 0.7199 - val_root_mean_squared_error: 0.7199 - lr: 0.0010\n",
      "Epoch 35/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6013 - root_mean_squared_error: 0.6013 - val_loss: 0.7247 - val_root_mean_squared_error: 0.7247 - lr: 0.0010\n",
      "Epoch 36/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5888 - root_mean_squared_error: 0.5888 - val_loss: 0.7146 - val_root_mean_squared_error: 0.7146 - lr: 0.0010\n",
      "Epoch 37/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5646 - root_mean_squared_error: 0.5646 - val_loss: 0.7145 - val_root_mean_squared_error: 0.7145 - lr: 0.0010\n",
      "Epoch 38/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5546 - root_mean_squared_error: 0.5546 - val_loss: 0.6868 - val_root_mean_squared_error: 0.6868 - lr: 0.0010\n",
      "Epoch 39/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.5459 - root_mean_squared_error: 0.5459 - val_loss: 0.6826 - val_root_mean_squared_error: 0.6826 - lr: 0.0010\n",
      "Epoch 40/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.5386 - root_mean_squared_error: 0.5386 - val_loss: 0.6698 - val_root_mean_squared_error: 0.6698 - lr: 0.0010\n",
      "Epoch 41/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5327 - root_mean_squared_error: 0.5327 - val_loss: 0.6655 - val_root_mean_squared_error: 0.6655 - lr: 0.0010\n",
      "Epoch 42/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5259 - root_mean_squared_error: 0.5259 - val_loss: 0.6704 - val_root_mean_squared_error: 0.6704 - lr: 0.0010\n",
      "Epoch 43/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5222 - root_mean_squared_error: 0.5222 - val_loss: 0.6617 - val_root_mean_squared_error: 0.6617 - lr: 0.0010\n",
      "Epoch 44/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5118 - root_mean_squared_error: 0.5118 - val_loss: 0.6633 - val_root_mean_squared_error: 0.6633 - lr: 0.0010\n",
      "Epoch 45/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5058 - root_mean_squared_error: 0.5058 - val_loss: 0.6551 - val_root_mean_squared_error: 0.6551 - lr: 0.0010\n",
      "Epoch 46/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4992 - root_mean_squared_error: 0.4992 - val_loss: 0.6392 - val_root_mean_squared_error: 0.6392 - lr: 0.0010\n",
      "Epoch 47/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4863 - root_mean_squared_error: 0.4863 - val_loss: 0.6432 - val_root_mean_squared_error: 0.6432 - lr: 0.0010\n",
      "Epoch 48/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4852 - root_mean_squared_error: 0.4852 - val_loss: 0.6438 - val_root_mean_squared_error: 0.6438 - lr: 0.0010\n",
      "Epoch 49/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4818 - root_mean_squared_error: 0.4818 - val_loss: 0.6344 - val_root_mean_squared_error: 0.6344 - lr: 0.0010\n",
      "Epoch 50/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4760 - root_mean_squared_error: 0.4760 - val_loss: 0.6462 - val_root_mean_squared_error: 0.6462 - lr: 0.0010\n",
      "Epoch 51/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4722 - root_mean_squared_error: 0.4722 - val_loss: 0.6348 - val_root_mean_squared_error: 0.6348 - lr: 0.0010\n",
      "Epoch 52/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4648 - root_mean_squared_error: 0.4648 - val_loss: 0.6259 - val_root_mean_squared_error: 0.6259 - lr: 0.0010\n",
      "Epoch 53/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4630 - root_mean_squared_error: 0.4630 - val_loss: 0.6325 - val_root_mean_squared_error: 0.6325 - lr: 0.0010\n",
      "Epoch 54/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4610 - root_mean_squared_error: 0.4610 - val_loss: 0.6285 - val_root_mean_squared_error: 0.6285 - lr: 0.0010\n",
      "Epoch 55/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4596 - root_mean_squared_error: 0.4596 - val_loss: 0.6324 - val_root_mean_squared_error: 0.6324 - lr: 0.0010\n",
      "Epoch 56/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4589 - root_mean_squared_error: 0.4589 - val_loss: 0.6255 - val_root_mean_squared_error: 0.6255 - lr: 0.0010\n",
      "Epoch 57/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4546 - root_mean_squared_error: 0.4546 - val_loss: 0.6292 - val_root_mean_squared_error: 0.6292 - lr: 0.0010\n",
      "Epoch 58/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4548 - root_mean_squared_error: 0.4548 - val_loss: 0.6266 - val_root_mean_squared_error: 0.6266 - lr: 0.0010\n",
      "Epoch 59/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4515 - root_mean_squared_error: 0.4515 - val_loss: 0.6316 - val_root_mean_squared_error: 0.6316 - lr: 0.0010\n",
      "Epoch 60/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4492 - root_mean_squared_error: 0.4492 - val_loss: 0.6204 - val_root_mean_squared_error: 0.6204 - lr: 0.0010\n",
      "Epoch 61/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4489 - root_mean_squared_error: 0.4489 - val_loss: 0.6350 - val_root_mean_squared_error: 0.6350 - lr: 0.0010\n",
      "Epoch 62/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4465 - root_mean_squared_error: 0.4465 - val_loss: 0.6208 - val_root_mean_squared_error: 0.6208 - lr: 0.0010\n",
      "Epoch 63/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4444 - root_mean_squared_error: 0.4444 - val_loss: 0.6172 - val_root_mean_squared_error: 0.6172 - lr: 0.0010\n",
      "Epoch 64/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4421 - root_mean_squared_error: 0.4421 - val_loss: 0.6264 - val_root_mean_squared_error: 0.6264 - lr: 0.0010\n",
      "Epoch 65/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4409 - root_mean_squared_error: 0.4409 - val_loss: 0.6476 - val_root_mean_squared_error: 0.6476 - lr: 0.0010\n",
      "Epoch 66/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4387 - root_mean_squared_error: 0.4387 - val_loss: 0.6220 - val_root_mean_squared_error: 0.6220 - lr: 0.0010\n",
      "Epoch 67/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4386 - root_mean_squared_error: 0.4386 - val_loss: 0.6132 - val_root_mean_squared_error: 0.6132 - lr: 0.0010\n",
      "Epoch 68/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4377 - root_mean_squared_error: 0.4377 - val_loss: 0.6253 - val_root_mean_squared_error: 0.6253 - lr: 0.0010\n",
      "Epoch 69/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.4414 - root_mean_squared_error: 0.4414 - val_loss: 0.6050 - val_root_mean_squared_error: 0.6050 - lr: 0.0010\n",
      "Epoch 70/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4281 - root_mean_squared_error: 0.4281 - val_loss: 0.6076 - val_root_mean_squared_error: 0.6076 - lr: 0.0010\n",
      "Epoch 71/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4222 - root_mean_squared_error: 0.4222 - val_loss: 0.5958 - val_root_mean_squared_error: 0.5958 - lr: 0.0010\n",
      "Epoch 72/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4167 - root_mean_squared_error: 0.4167 - val_loss: 0.5956 - val_root_mean_squared_error: 0.5956 - lr: 0.0010\n",
      "Epoch 73/192\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.4135 - root_mean_squared_error: 0.4135 - val_loss: 0.5971 - val_root_mean_squared_error: 0.5971 - lr: 0.0010\n",
      "Epoch 74/192\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.4133 - root_mean_squared_error: 0.4133 - val_loss: 0.5921 - val_root_mean_squared_error: 0.5921 - lr: 0.0010\n",
      "Epoch 75/192\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.4108 - root_mean_squared_error: 0.4108 - val_loss: 0.5915 - val_root_mean_squared_error: 0.5915 - lr: 0.0010\n",
      "Epoch 76/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4065 - root_mean_squared_error: 0.4065 - val_loss: 0.6023 - val_root_mean_squared_error: 0.6023 - lr: 0.0010\n",
      "Epoch 77/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4078 - root_mean_squared_error: 0.4078 - val_loss: 0.5972 - val_root_mean_squared_error: 0.5972 - lr: 0.0010\n",
      "Epoch 78/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4082 - root_mean_squared_error: 0.4082 - val_loss: 0.5959 - val_root_mean_squared_error: 0.5959 - lr: 0.0010\n",
      "Epoch 79/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4029 - root_mean_squared_error: 0.4029 - val_loss: 0.5946 - val_root_mean_squared_error: 0.5946 - lr: 0.0010\n",
      "Epoch 80/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4031 - root_mean_squared_error: 0.4031 - val_loss: 0.5985 - val_root_mean_squared_error: 0.5985 - lr: 0.0010\n",
      "Epoch 81/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4039 - root_mean_squared_error: 0.4039 - val_loss: 0.5923 - val_root_mean_squared_error: 0.5923 - lr: 0.0010\n",
      "Epoch 82/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4028 - root_mean_squared_error: 0.4028 - val_loss: 0.5922 - val_root_mean_squared_error: 0.5922 - lr: 0.0010\n",
      "Epoch 83/192\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3985 - root_mean_squared_error: 0.3985\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.3985 - root_mean_squared_error: 0.3985 - val_loss: 0.5997 - val_root_mean_squared_error: 0.5997 - lr: 0.0010\n",
      "5644/5644 [==============================] - 11s 2ms/step\n",
      "Epoch 1/192\n",
      "120/120 [==============================] - 8s 31ms/step - loss: 3.6623 - root_mean_squared_error: 3.6623 - val_loss: 4.4205 - val_root_mean_squared_error: 4.4205 - lr: 0.0010\n",
      "Epoch 2/192\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 2.1413 - root_mean_squared_error: 2.1413 - val_loss: 2.6086 - val_root_mean_squared_error: 2.6086 - lr: 0.0010\n",
      "Epoch 3/192\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 1.8041 - root_mean_squared_error: 1.8041 - val_loss: 1.6518 - val_root_mean_squared_error: 1.6518 - lr: 0.0010\n",
      "Epoch 4/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.5770 - root_mean_squared_error: 1.5770 - val_loss: 1.4883 - val_root_mean_squared_error: 1.4883 - lr: 0.0010\n",
      "Epoch 5/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.4238 - root_mean_squared_error: 1.4238 - val_loss: 1.3877 - val_root_mean_squared_error: 1.3877 - lr: 0.0010\n",
      "Epoch 6/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.2729 - root_mean_squared_error: 1.2729 - val_loss: 1.2030 - val_root_mean_squared_error: 1.2030 - lr: 0.0010\n",
      "Epoch 7/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.2034 - root_mean_squared_error: 1.2034 - val_loss: 1.1401 - val_root_mean_squared_error: 1.1401 - lr: 0.0010\n",
      "Epoch 8/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.1423 - root_mean_squared_error: 1.1423 - val_loss: 1.1326 - val_root_mean_squared_error: 1.1326 - lr: 0.0010\n",
      "Epoch 9/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.0809 - root_mean_squared_error: 1.0809 - val_loss: 1.0369 - val_root_mean_squared_error: 1.0369 - lr: 0.0010\n",
      "Epoch 10/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.0212 - root_mean_squared_error: 1.0212 - val_loss: 0.9884 - val_root_mean_squared_error: 0.9884 - lr: 0.0010\n",
      "Epoch 11/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.9854 - root_mean_squared_error: 0.9854 - val_loss: 0.9576 - val_root_mean_squared_error: 0.9576 - lr: 0.0010\n",
      "Epoch 12/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.9503 - root_mean_squared_error: 0.9503 - val_loss: 0.9491 - val_root_mean_squared_error: 0.9491 - lr: 0.0010\n",
      "Epoch 13/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.9257 - root_mean_squared_error: 0.9257 - val_loss: 0.9419 - val_root_mean_squared_error: 0.9419 - lr: 0.0010\n",
      "Epoch 14/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.8918 - root_mean_squared_error: 0.8918 - val_loss: 0.9008 - val_root_mean_squared_error: 0.9008 - lr: 0.0010\n",
      "Epoch 15/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8703 - root_mean_squared_error: 0.8703 - val_loss: 0.8559 - val_root_mean_squared_error: 0.8559 - lr: 0.0010\n",
      "Epoch 16/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8401 - root_mean_squared_error: 0.8401 - val_loss: 0.8491 - val_root_mean_squared_error: 0.8491 - lr: 0.0010\n",
      "Epoch 17/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8258 - root_mean_squared_error: 0.8258 - val_loss: 0.8281 - val_root_mean_squared_error: 0.8281 - lr: 0.0010\n",
      "Epoch 18/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8128 - root_mean_squared_error: 0.8128 - val_loss: 0.8166 - val_root_mean_squared_error: 0.8166 - lr: 0.0010\n",
      "Epoch 19/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7871 - root_mean_squared_error: 0.7871 - val_loss: 0.8168 - val_root_mean_squared_error: 0.8168 - lr: 0.0010\n",
      "Epoch 20/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.7747 - root_mean_squared_error: 0.7747 - val_loss: 0.8144 - val_root_mean_squared_error: 0.8144 - lr: 0.0010\n",
      "Epoch 21/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7579 - root_mean_squared_error: 0.7579 - val_loss: 0.8019 - val_root_mean_squared_error: 0.8019 - lr: 0.0010\n",
      "Epoch 22/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7356 - root_mean_squared_error: 0.7356 - val_loss: 0.7881 - val_root_mean_squared_error: 0.7881 - lr: 0.0010\n",
      "Epoch 23/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7296 - root_mean_squared_error: 0.7296 - val_loss: 0.7743 - val_root_mean_squared_error: 0.7743 - lr: 0.0010\n",
      "Epoch 24/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7102 - root_mean_squared_error: 0.7102 - val_loss: 0.7713 - val_root_mean_squared_error: 0.7713 - lr: 0.0010\n",
      "Epoch 25/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7018 - root_mean_squared_error: 0.7018 - val_loss: 0.7644 - val_root_mean_squared_error: 0.7644 - lr: 0.0010\n",
      "Epoch 26/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6911 - root_mean_squared_error: 0.6911 - val_loss: 0.7646 - val_root_mean_squared_error: 0.7646 - lr: 0.0010\n",
      "Epoch 27/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6724 - root_mean_squared_error: 0.6724 - val_loss: 0.7535 - val_root_mean_squared_error: 0.7535 - lr: 0.0010\n",
      "Epoch 28/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.6550 - root_mean_squared_error: 0.6550 - val_loss: 0.7412 - val_root_mean_squared_error: 0.7412 - lr: 0.0010\n",
      "Epoch 29/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.6426 - root_mean_squared_error: 0.6426 - val_loss: 0.7265 - val_root_mean_squared_error: 0.7265 - lr: 0.0010\n",
      "Epoch 30/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.6307 - root_mean_squared_error: 0.6307 - val_loss: 0.7248 - val_root_mean_squared_error: 0.7248 - lr: 0.0010\n",
      "Epoch 31/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6170 - root_mean_squared_error: 0.6170 - val_loss: 0.7149 - val_root_mean_squared_error: 0.7149 - lr: 0.0010\n",
      "Epoch 32/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5985 - root_mean_squared_error: 0.5985 - val_loss: 0.7368 - val_root_mean_squared_error: 0.7368 - lr: 0.0010\n",
      "Epoch 33/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5912 - root_mean_squared_error: 0.5912 - val_loss: 0.7125 - val_root_mean_squared_error: 0.7125 - lr: 0.0010\n",
      "Epoch 34/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5833 - root_mean_squared_error: 0.5833 - val_loss: 0.7020 - val_root_mean_squared_error: 0.7020 - lr: 0.0010\n",
      "Epoch 35/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.5590 - root_mean_squared_error: 0.5590 - val_loss: 0.6707 - val_root_mean_squared_error: 0.6707 - lr: 0.0010\n",
      "Epoch 36/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.5524 - root_mean_squared_error: 0.5524 - val_loss: 0.6871 - val_root_mean_squared_error: 0.6871 - lr: 0.0010\n",
      "Epoch 37/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5396 - root_mean_squared_error: 0.5396 - val_loss: 0.6562 - val_root_mean_squared_error: 0.6562 - lr: 0.0010\n",
      "Epoch 38/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5224 - root_mean_squared_error: 0.5224 - val_loss: 0.6543 - val_root_mean_squared_error: 0.6543 - lr: 0.0010\n",
      "Epoch 39/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5140 - root_mean_squared_error: 0.5140 - val_loss: 0.6455 - val_root_mean_squared_error: 0.6455 - lr: 0.0010\n",
      "Epoch 40/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5063 - root_mean_squared_error: 0.5063 - val_loss: 0.6386 - val_root_mean_squared_error: 0.6386 - lr: 0.0010\n",
      "Epoch 41/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5001 - root_mean_squared_error: 0.5001 - val_loss: 0.6422 - val_root_mean_squared_error: 0.6422 - lr: 0.0010\n",
      "Epoch 42/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.5011 - root_mean_squared_error: 0.5011 - val_loss: 0.6371 - val_root_mean_squared_error: 0.6371 - lr: 0.0010\n",
      "Epoch 43/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4949 - root_mean_squared_error: 0.4949 - val_loss: 0.6384 - val_root_mean_squared_error: 0.6384 - lr: 0.0010\n",
      "Epoch 44/192\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.4916 - root_mean_squared_error: 0.4916 - val_loss: 0.6432 - val_root_mean_squared_error: 0.6432 - lr: 0.0010\n",
      "Epoch 45/192\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.4876 - root_mean_squared_error: 0.4876 - val_loss: 0.6380 - val_root_mean_squared_error: 0.6380 - lr: 0.0010\n",
      "Epoch 46/192\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.4854 - root_mean_squared_error: 0.4854 - val_loss: 0.6402 - val_root_mean_squared_error: 0.6402 - lr: 0.0010\n",
      "Epoch 47/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4821 - root_mean_squared_error: 0.4821 - val_loss: 0.6351 - val_root_mean_squared_error: 0.6351 - lr: 0.0010\n",
      "Epoch 48/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4787 - root_mean_squared_error: 0.4787 - val_loss: 0.6286 - val_root_mean_squared_error: 0.6286 - lr: 0.0010\n",
      "Epoch 49/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4726 - root_mean_squared_error: 0.4726 - val_loss: 0.6469 - val_root_mean_squared_error: 0.6469 - lr: 0.0010\n",
      "Epoch 50/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4711 - root_mean_squared_error: 0.4711 - val_loss: 0.6337 - val_root_mean_squared_error: 0.6337 - lr: 0.0010\n",
      "Epoch 51/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4674 - root_mean_squared_error: 0.4674 - val_loss: 0.6352 - val_root_mean_squared_error: 0.6352 - lr: 0.0010\n",
      "Epoch 52/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4669 - root_mean_squared_error: 0.4669 - val_loss: 0.6277 - val_root_mean_squared_error: 0.6277 - lr: 0.0010\n",
      "Epoch 53/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4666 - root_mean_squared_error: 0.4666 - val_loss: 0.6248 - val_root_mean_squared_error: 0.6248 - lr: 0.0010\n",
      "Epoch 54/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4627 - root_mean_squared_error: 0.4627 - val_loss: 0.6283 - val_root_mean_squared_error: 0.6283 - lr: 0.0010\n",
      "Epoch 55/192\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 0.4607 - root_mean_squared_error: 0.4607 - val_loss: 0.6321 - val_root_mean_squared_error: 0.6321 - lr: 0.0010\n",
      "Epoch 56/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4577 - root_mean_squared_error: 0.4577 - val_loss: 0.6421 - val_root_mean_squared_error: 0.6421 - lr: 0.0010\n",
      "Epoch 57/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4571 - root_mean_squared_error: 0.4571 - val_loss: 0.6236 - val_root_mean_squared_error: 0.6236 - lr: 0.0010\n",
      "Epoch 58/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4544 - root_mean_squared_error: 0.4544 - val_loss: 0.6271 - val_root_mean_squared_error: 0.6271 - lr: 0.0010\n",
      "Epoch 59/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4519 - root_mean_squared_error: 0.4519 - val_loss: 0.6206 - val_root_mean_squared_error: 0.6206 - lr: 0.0010\n",
      "Epoch 60/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4492 - root_mean_squared_error: 0.4492 - val_loss: 0.6185 - val_root_mean_squared_error: 0.6185 - lr: 0.0010\n",
      "Epoch 61/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4479 - root_mean_squared_error: 0.4479 - val_loss: 0.6248 - val_root_mean_squared_error: 0.6248 - lr: 0.0010\n",
      "Epoch 62/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4444 - root_mean_squared_error: 0.4444 - val_loss: 0.6247 - val_root_mean_squared_error: 0.6247 - lr: 0.0010\n",
      "Epoch 63/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4441 - root_mean_squared_error: 0.4441 - val_loss: 0.6202 - val_root_mean_squared_error: 0.6202 - lr: 0.0010\n",
      "Epoch 64/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4421 - root_mean_squared_error: 0.4421 - val_loss: 0.6223 - val_root_mean_squared_error: 0.6223 - lr: 0.0010\n",
      "Epoch 65/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4405 - root_mean_squared_error: 0.4405 - val_loss: 0.6204 - val_root_mean_squared_error: 0.6204 - lr: 0.0010\n",
      "Epoch 66/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4400 - root_mean_squared_error: 0.4400 - val_loss: 0.6314 - val_root_mean_squared_error: 0.6314 - lr: 0.0010\n",
      "Epoch 67/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4378 - root_mean_squared_error: 0.4378 - val_loss: 0.6195 - val_root_mean_squared_error: 0.6195 - lr: 0.0010\n",
      "Epoch 68/192\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.4366 - root_mean_squared_error: 0.4366\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4366 - root_mean_squared_error: 0.4366 - val_loss: 0.6234 - val_root_mean_squared_error: 0.6234 - lr: 0.0010\n",
      "5644/5644 [==============================] - 11s 2ms/step\n",
      "Epoch 1/192\n",
      "120/120 [==============================] - 8s 29ms/step - loss: 3.4767 - root_mean_squared_error: 3.4767 - val_loss: 2.6969 - val_root_mean_squared_error: 2.6969 - lr: 0.0010\n",
      "Epoch 2/192\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 2.0929 - root_mean_squared_error: 2.0929 - val_loss: 1.9707 - val_root_mean_squared_error: 1.9707 - lr: 0.0010\n",
      "Epoch 3/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.7518 - root_mean_squared_error: 1.7518 - val_loss: 1.9194 - val_root_mean_squared_error: 1.9194 - lr: 0.0010\n",
      "Epoch 4/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.5187 - root_mean_squared_error: 1.5187 - val_loss: 1.5724 - val_root_mean_squared_error: 1.5724 - lr: 0.0010\n",
      "Epoch 5/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.3651 - root_mean_squared_error: 1.3651 - val_loss: 1.3101 - val_root_mean_squared_error: 1.3101 - lr: 0.0010\n",
      "Epoch 6/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1.2596 - root_mean_squared_error: 1.2596 - val_loss: 1.2514 - val_root_mean_squared_error: 1.2514 - lr: 0.0010\n",
      "Epoch 7/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.1675 - root_mean_squared_error: 1.1675 - val_loss: 1.1489 - val_root_mean_squared_error: 1.1489 - lr: 0.0010\n",
      "Epoch 8/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.0903 - root_mean_squared_error: 1.0903 - val_loss: 1.0649 - val_root_mean_squared_error: 1.0649 - lr: 0.0010\n",
      "Epoch 9/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.0385 - root_mean_squared_error: 1.0385 - val_loss: 1.0808 - val_root_mean_squared_error: 1.0808 - lr: 0.0010\n",
      "Epoch 10/192\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.9977 - root_mean_squared_error: 0.9977 - val_loss: 0.9815 - val_root_mean_squared_error: 0.9815 - lr: 0.0010\n",
      "Epoch 11/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.9678 - root_mean_squared_error: 0.9678 - val_loss: 0.9520 - val_root_mean_squared_error: 0.9520 - lr: 0.0010\n",
      "Epoch 12/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.9303 - root_mean_squared_error: 0.9303 - val_loss: 0.9660 - val_root_mean_squared_error: 0.9660 - lr: 0.0010\n",
      "Epoch 13/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.9068 - root_mean_squared_error: 0.9068 - val_loss: 0.8981 - val_root_mean_squared_error: 0.8981 - lr: 0.0010\n",
      "Epoch 14/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.8851 - root_mean_squared_error: 0.8851 - val_loss: 0.8958 - val_root_mean_squared_error: 0.8958 - lr: 0.0010\n",
      "Epoch 15/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8775 - root_mean_squared_error: 0.8775 - val_loss: 0.8932 - val_root_mean_squared_error: 0.8932 - lr: 0.0010\n",
      "Epoch 16/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.8573 - root_mean_squared_error: 0.8573 - val_loss: 0.8685 - val_root_mean_squared_error: 0.8685 - lr: 0.0010\n",
      "Epoch 17/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.8347 - root_mean_squared_error: 0.8347 - val_loss: 0.8706 - val_root_mean_squared_error: 0.8706 - lr: 0.0010\n",
      "Epoch 18/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.8164 - root_mean_squared_error: 0.8164 - val_loss: 0.9156 - val_root_mean_squared_error: 0.9156 - lr: 0.0010\n",
      "Epoch 19/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.8010 - root_mean_squared_error: 0.8010 - val_loss: 0.8522 - val_root_mean_squared_error: 0.8522 - lr: 0.0010\n",
      "Epoch 20/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7790 - root_mean_squared_error: 0.7790 - val_loss: 0.8140 - val_root_mean_squared_error: 0.8140 - lr: 0.0010\n",
      "Epoch 21/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7644 - root_mean_squared_error: 0.7644 - val_loss: 0.8276 - val_root_mean_squared_error: 0.8276 - lr: 0.0010\n",
      "Epoch 22/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7483 - root_mean_squared_error: 0.7483 - val_loss: 0.7958 - val_root_mean_squared_error: 0.7958 - lr: 0.0010\n",
      "Epoch 23/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.7429 - root_mean_squared_error: 0.7429 - val_loss: 0.7840 - val_root_mean_squared_error: 0.7840 - lr: 0.0010\n",
      "Epoch 24/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7306 - root_mean_squared_error: 0.7306 - val_loss: 0.7837 - val_root_mean_squared_error: 0.7837 - lr: 0.0010\n",
      "Epoch 25/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.7224 - root_mean_squared_error: 0.7224 - val_loss: 0.7812 - val_root_mean_squared_error: 0.7812 - lr: 0.0010\n",
      "Epoch 26/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7069 - root_mean_squared_error: 0.7069 - val_loss: 0.7812 - val_root_mean_squared_error: 0.7812 - lr: 0.0010\n",
      "Epoch 27/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.6933 - root_mean_squared_error: 0.6933 - val_loss: 0.7586 - val_root_mean_squared_error: 0.7586 - lr: 0.0010\n",
      "Epoch 28/192\n",
      "120/120 [==============================] - 5s 46ms/step - loss: 0.6826 - root_mean_squared_error: 0.6826 - val_loss: 0.7664 - val_root_mean_squared_error: 0.7664 - lr: 0.0010\n",
      "Epoch 29/192\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.6797 - root_mean_squared_error: 0.6797 - val_loss: 0.7642 - val_root_mean_squared_error: 0.7642 - lr: 0.0010\n",
      "Epoch 30/192\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.6567 - root_mean_squared_error: 0.6567 - val_loss: 0.7438 - val_root_mean_squared_error: 0.7438 - lr: 0.0010\n",
      "Epoch 31/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6519 - root_mean_squared_error: 0.6519 - val_loss: 0.7495 - val_root_mean_squared_error: 0.7495 - lr: 0.0010\n",
      "Epoch 32/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6446 - root_mean_squared_error: 0.6446 - val_loss: 0.7406 - val_root_mean_squared_error: 0.7406 - lr: 0.0010\n",
      "Epoch 33/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6378 - root_mean_squared_error: 0.6378 - val_loss: 0.7412 - val_root_mean_squared_error: 0.7412 - lr: 0.0010\n",
      "Epoch 34/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6350 - root_mean_squared_error: 0.6350 - val_loss: 0.7359 - val_root_mean_squared_error: 0.7359 - lr: 0.0010\n",
      "Epoch 35/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6276 - root_mean_squared_error: 0.6276 - val_loss: 0.7421 - val_root_mean_squared_error: 0.7421 - lr: 0.0010\n",
      "Epoch 36/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.6129 - root_mean_squared_error: 0.6129 - val_loss: 0.7328 - val_root_mean_squared_error: 0.7328 - lr: 0.0010\n",
      "Epoch 37/192\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 0.6091 - root_mean_squared_error: 0.6091 - val_loss: 0.7374 - val_root_mean_squared_error: 0.7374 - lr: 0.0010\n",
      "Epoch 38/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5948 - root_mean_squared_error: 0.5948 - val_loss: 0.7241 - val_root_mean_squared_error: 0.7241 - lr: 0.0010\n",
      "Epoch 39/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5851 - root_mean_squared_error: 0.5851 - val_loss: 0.7093 - val_root_mean_squared_error: 0.7093 - lr: 0.0010\n",
      "Epoch 40/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5709 - root_mean_squared_error: 0.5709 - val_loss: 0.6970 - val_root_mean_squared_error: 0.6970 - lr: 0.0010\n",
      "Epoch 41/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5618 - root_mean_squared_error: 0.5618 - val_loss: 0.7043 - val_root_mean_squared_error: 0.7043 - lr: 0.0010\n",
      "Epoch 42/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5341 - root_mean_squared_error: 0.5341 - val_loss: 0.6703 - val_root_mean_squared_error: 0.6703 - lr: 0.0010\n",
      "Epoch 43/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5289 - root_mean_squared_error: 0.5289 - val_loss: 0.6712 - val_root_mean_squared_error: 0.6712 - lr: 0.0010\n",
      "Epoch 44/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.5193 - root_mean_squared_error: 0.5193 - val_loss: 0.6652 - val_root_mean_squared_error: 0.6652 - lr: 0.0010\n",
      "Epoch 45/192\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.5044 - root_mean_squared_error: 0.5044 - val_loss: 0.6515 - val_root_mean_squared_error: 0.6515 - lr: 0.0010\n",
      "Epoch 46/192\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.5034 - root_mean_squared_error: 0.5034 - val_loss: 0.6659 - val_root_mean_squared_error: 0.6659 - lr: 0.0010\n",
      "Epoch 47/192\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.4991 - root_mean_squared_error: 0.4991 - val_loss: 0.6461 - val_root_mean_squared_error: 0.6461 - lr: 0.0010\n",
      "Epoch 48/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4950 - root_mean_squared_error: 0.4950 - val_loss: 0.6491 - val_root_mean_squared_error: 0.6491 - lr: 0.0010\n",
      "Epoch 49/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4914 - root_mean_squared_error: 0.4914 - val_loss: 0.6448 - val_root_mean_squared_error: 0.6448 - lr: 0.0010\n",
      "Epoch 50/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4914 - root_mean_squared_error: 0.4914 - val_loss: 0.6450 - val_root_mean_squared_error: 0.6450 - lr: 0.0010\n",
      "Epoch 51/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4866 - root_mean_squared_error: 0.4866 - val_loss: 0.6512 - val_root_mean_squared_error: 0.6512 - lr: 0.0010\n",
      "Epoch 52/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4849 - root_mean_squared_error: 0.4849 - val_loss: 0.6430 - val_root_mean_squared_error: 0.6430 - lr: 0.0010\n",
      "Epoch 53/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4820 - root_mean_squared_error: 0.4820 - val_loss: 0.6451 - val_root_mean_squared_error: 0.6451 - lr: 0.0010\n",
      "Epoch 54/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4776 - root_mean_squared_error: 0.4776 - val_loss: 0.6417 - val_root_mean_squared_error: 0.6417 - lr: 0.0010\n",
      "Epoch 55/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4790 - root_mean_squared_error: 0.4790 - val_loss: 0.6434 - val_root_mean_squared_error: 0.6434 - lr: 0.0010\n",
      "Epoch 56/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4804 - root_mean_squared_error: 0.4804 - val_loss: 0.6435 - val_root_mean_squared_error: 0.6435 - lr: 0.0010\n",
      "Epoch 57/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4763 - root_mean_squared_error: 0.4763 - val_loss: 0.6426 - val_root_mean_squared_error: 0.6426 - lr: 0.0010\n",
      "Epoch 58/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4729 - root_mean_squared_error: 0.4729 - val_loss: 0.6412 - val_root_mean_squared_error: 0.6412 - lr: 0.0010\n",
      "Epoch 59/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4585 - root_mean_squared_error: 0.4585 - val_loss: 0.6387 - val_root_mean_squared_error: 0.6387 - lr: 0.0010\n",
      "Epoch 60/192\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.4544 - root_mean_squared_error: 0.4544 - val_loss: 0.6312 - val_root_mean_squared_error: 0.6312 - lr: 0.0010\n",
      "Epoch 61/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4512 - root_mean_squared_error: 0.4512 - val_loss: 0.6323 - val_root_mean_squared_error: 0.6323 - lr: 0.0010\n",
      "Epoch 62/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4484 - root_mean_squared_error: 0.4484 - val_loss: 0.6238 - val_root_mean_squared_error: 0.6238 - lr: 0.0010\n",
      "Epoch 63/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4491 - root_mean_squared_error: 0.4491 - val_loss: 0.6249 - val_root_mean_squared_error: 0.6249 - lr: 0.0010\n",
      "Epoch 64/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4504 - root_mean_squared_error: 0.4504 - val_loss: 0.6271 - val_root_mean_squared_error: 0.6271 - lr: 0.0010\n",
      "Epoch 65/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4440 - root_mean_squared_error: 0.4440 - val_loss: 0.6241 - val_root_mean_squared_error: 0.6241 - lr: 0.0010\n",
      "Epoch 66/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4447 - root_mean_squared_error: 0.4447 - val_loss: 0.6259 - val_root_mean_squared_error: 0.6259 - lr: 0.0010\n",
      "Epoch 67/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4414 - root_mean_squared_error: 0.4414 - val_loss: 0.6263 - val_root_mean_squared_error: 0.6263 - lr: 0.0010\n",
      "Epoch 68/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4403 - root_mean_squared_error: 0.4403 - val_loss: 0.6221 - val_root_mean_squared_error: 0.6221 - lr: 0.0010\n",
      "Epoch 69/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4446 - root_mean_squared_error: 0.4446 - val_loss: 0.6240 - val_root_mean_squared_error: 0.6240 - lr: 0.0010\n",
      "Epoch 70/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4361 - root_mean_squared_error: 0.4361 - val_loss: 0.6235 - val_root_mean_squared_error: 0.6235 - lr: 0.0010\n",
      "Epoch 71/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4365 - root_mean_squared_error: 0.4365 - val_loss: 0.6276 - val_root_mean_squared_error: 0.6276 - lr: 0.0010\n",
      "Epoch 72/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4331 - root_mean_squared_error: 0.4331 - val_loss: 0.6198 - val_root_mean_squared_error: 0.6198 - lr: 0.0010\n",
      "Epoch 73/192\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 0.4324 - root_mean_squared_error: 0.4324 - val_loss: 0.6227 - val_root_mean_squared_error: 0.6227 - lr: 0.0010\n",
      "Epoch 74/192\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 0.4305 - root_mean_squared_error: 0.4305 - val_loss: 0.6211 - val_root_mean_squared_error: 0.6211 - lr: 0.0010\n",
      "Epoch 75/192\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.4272 - root_mean_squared_error: 0.4272 - val_loss: 0.6177 - val_root_mean_squared_error: 0.6177 - lr: 0.0010\n",
      "Epoch 76/192\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.4282 - root_mean_squared_error: 0.4282 - val_loss: 0.6232 - val_root_mean_squared_error: 0.6232 - lr: 0.0010\n",
      "Epoch 77/192\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.4249 - root_mean_squared_error: 0.4249 - val_loss: 0.6186 - val_root_mean_squared_error: 0.6186 - lr: 0.0010\n",
      "Epoch 78/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4238 - root_mean_squared_error: 0.4238 - val_loss: 0.6190 - val_root_mean_squared_error: 0.6190 - lr: 0.0010\n",
      "Epoch 79/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4252 - root_mean_squared_error: 0.4252 - val_loss: 0.6217 - val_root_mean_squared_error: 0.6217 - lr: 0.0010\n",
      "Epoch 80/192\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.4249 - root_mean_squared_error: 0.4249 - val_loss: 0.6316 - val_root_mean_squared_error: 0.6316 - lr: 0.0010\n",
      "Epoch 81/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4233 - root_mean_squared_error: 0.4233 - val_loss: 0.6183 - val_root_mean_squared_error: 0.6183 - lr: 0.0010\n",
      "Epoch 82/192\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4170 - root_mean_squared_error: 0.4170 - val_loss: 0.6238 - val_root_mean_squared_error: 0.6238 - lr: 0.0010\n",
      "Epoch 83/192\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4126 - root_mean_squared_error: 0.4126\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.4126 - root_mean_squared_error: 0.4126 - val_loss: 0.6183 - val_root_mean_squared_error: 0.6183 - lr: 0.0010\n",
      "5644/5644 [==============================] - 11s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "fold = 0\n",
    "y_preds = []\n",
    "models = []\n",
    "for train_indices, test_indices in kfold.split(X, y):\n",
    "# for fold, (train_indices, test_indices) in tqdm(enumerate(splits)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    # model\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = create_model(X.shape[-1], y.shape[-1], encoder)\n",
    "    \n",
    "    # callbacks\n",
    "    er = tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, monitor='val_loss')\n",
    "    ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1)\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'./model_{2020}_{fold}.hdf5', save_weights_only=True, verbose=0, monitor='root_mean_squared_error', save_best_only=True)\n",
    "    nn_callbacks = [er, ReduceLR, model_checkpoint_callback]\n",
    "    \n",
    "#     valid_pred = model.predict(X[valid_idx, :]).reshape(1, -1)[0]\n",
    "#     valid_mse = mean_squared_error(y[valid_idx], valid_pred)\n",
    "#     valid_mae = mean_absolute_error(y[valid_idx], valid_pred)\n",
    "#     valid_src = stats.spearmanr(y[valid_idx], valid_pred)[0]\n",
    "\n",
    "#     print(f'Fold-{fold}: RMSE={valid_mse}, MAE={valid_mae},SRC={valid_src} ')\n",
    "    \n",
    "#     y_pred = model.predict(test_df).reshape(1, -1)[0]\n",
    "#     y_preds.append(y_pred)\n",
    "    # models.append(model)\n",
    "    model.save(f\"./dae_1dcnn_f{fold}.h5\")\n",
    "    # rmse_lst.append(valid_mse)\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train, validation_data=(X_test,y_test), \n",
    "              epochs=192, batch_size=2048, callbacks=nn_callbacks)\n",
    "    y_pred = model.predict(df_test).reshape(1, -1)[0]\n",
    "    y_preds.append(y_pred)\n",
    "    # model.predict(df_test)\n",
    "    # models.append(model)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1565c8ed-df5c-4f68-b00e-30847a97e7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 8.81501  , 10.458895 ,  9.324839 , ...,  7.6694593,  9.755777 ,\n",
       "         5.697639 ], dtype=float32),\n",
       " array([ 9.409686 , 10.5654955, 10.604354 , ...,  8.048788 ,  9.741979 ,\n",
       "         6.3828497], dtype=float32),\n",
       " array([ 8.611053 , 11.598322 ,  9.336557 , ...,  7.656889 ,  9.716085 ,\n",
       "         7.8818555], dtype=float32),\n",
       " array([ 8.94466 , 10.535761,  9.877227, ...,  7.516124,  9.081009,\n",
       "         7.525093], dtype=float32),\n",
       " array([ 7.6713247, 11.206317 ,  9.815075 , ...,  8.012328 , 10.056163 ,\n",
       "         6.2926197], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f668c826-f92c-4645-a058-f34f4363d669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(valid_ans,columns=['dae_nn_mean']).to_csv('./dae_nn_mean.csv',header=True,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d2ea5c-7f61-4507-ae53-d6d32e0871de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.690348 , 10.872957 ,  9.79161  , ...,  7.7807183,  9.670203 ,\n",
       "        6.756011 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ans = np.mean(y_preds, axis=0)\n",
    "valid_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34f821-c484-4c49-ae84-a2eda5edff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Uid', 'Uid_count', 'Category', 'Subcategory', 'Concept', 'Title_len',\n",
    "#        'Title_number', 'Alltags_len', 'Alltags_number', 'img_length',\n",
    "#        'img_width', 'pixel', 'img_model', 'svd_mode_t_0', 'svd_mode_t_1',\n",
    "#        'svd_mode_t_2', 'svd_mode_t_3', 'svd_mode_t_4', 'svd_mode_t_5',\n",
    "#        'svd_mode_t_6', 'svd_mode_t_7', 'svd_mode_t_8', 'svd_mode_t_9',\n",
    "#        'svd_mode_t_10', 'svd_mode_t_11', 'svd_mode_t_12', 'svd_mode_t_13',\n",
    "#        'svd_mode_t_14', 'svd_mode_t_15', 'svd_mode_t_16', 'svd_mode_t_17',\n",
    "#        'svd_mode_t_18', 'svd_mode_t_19', 'svd_mode_0', 'svd_mode_1',\n",
    "#        'svd_mode_2', 'svd_mode_3', 'svd_mode_4', 'svd_mode_5', 'svd_mode_6',\n",
    "#        'svd_mode_7', 'svd_mode_8', 'svd_mode_9', 'svd_mode_10', 'svd_mode_11',\n",
    "#        'svd_mode_12', 'svd_mode_13', 'svd_mode_14', 'svd_mode_15',\n",
    "#        'svd_mode_16', 'svd_mode_17', 'svd_mode_18', 'svd_mode_19', 'Mediatype',\n",
    "#        'hour', 'day', 'weekday', 'week_hour', 'year_weekday', 'Longitude',\n",
    "#        'Latitude', 'Geoaccuracy', 'photo_count', 'ispro', 'firstdate',\n",
    "#        'firstweek', 'firstmonth', 'firstdatetaken', 'firstdatetakenweek',\n",
    "#        'firstdatetakenmonth', 'totalViews', 'totalTags', 'totalGeotagged',\n",
    "#        'totalFaves', 'totalInGroup', 'photoCount', 'meanView', 'meanTags',\n",
    "#        'meanFaves', 'followerCount', 'followingCount', 'Ispublic', 'label',\n",
    "#        'img_file', 'Category.1', 'Concept.1', 'Subcategory.1', 'Alltags',\n",
    "#        'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71053092-c226-4393-814b-4b3561b606af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # seed_everything()\n",
    "\n",
    "# #kf = StratifiedKFold(5, shuffle=True, random_state=GCF.SEED)\n",
    "# # kf = TimeSeriesSplit(n_splits=GCF.N_FOLDS, max_train_size=GCF.N_TRAIN)\n",
    "# from scipy import stats\n",
    "# from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error\n",
    "# from scipy import stats\n",
    "# rmse_lst, score_lst = [], []\n",
    "# #oof = np.zeros((len(y),))\n",
    "# #for fold, (train_idx, valid_idx) in enumerate(kf.split(X, investment_id)):\n",
    "\n",
    "# kfold = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "# fold = 0\n",
    "\n",
    "# for train_idx, valid_idx in kfold.split(X, y):\n",
    "#     model = create_model()\n",
    "\n",
    "#     early_stopping = keras.callbacks.EarlyStopping(\n",
    "#         monitor='root_mean_squared_error',\n",
    "#         patience=GCF.EARLY_STOPPING_PATIENCE,\n",
    "#         min_delta=GCF.EARLY_STOPPING_MIN_DELTA,\n",
    "#         restore_best_weights=True,\n",
    "#     )\n",
    "#     reduce_lr = ReduceLROnPlateau(\n",
    "#                         #monitor='val_loss',\n",
    "#                         monitor='root_mean_squared_error',\n",
    "#                         factor=0.5,\n",
    "#                         patience=3,\n",
    "#                         min_lr=1e-5,\n",
    "#                         verbose=1\n",
    "#     )\n",
    "\n",
    "#     model.fit(\n",
    "#         X[train_idx, :], y[train_idx],\n",
    "#         validation_data=(X[valid_idx, :], y[valid_idx]),\n",
    "#         batch_size=GCF.BATCH_SIZE,\n",
    "#         epochs=GCF.N_EPOCHS,\n",
    "#         callbacks=[early_stopping, reduce_lr],\n",
    "#     )\n",
    "    \n",
    "#     valid_pred = model.predict(X[valid_idx, :]).reshape(1, -1)[0]\n",
    "#     valid_mse = mean_squared_error(y[valid_idx], valid_pred)\n",
    "#     valid_mae = mean_absolute_error(y[valid_idx], valid_pred)\n",
    "#     valid_src = stats.spearmanr(y[valid_idx], valid_pred)[0]\n",
    "#     print(f'Fold-{fold}: RMSR={valid_mse}, MAE={valid_mae},SRC={valid_src} ')\n",
    "# #     oof_train[valid_index] = model.predict(X_val).reshape(1, -1)[0]\n",
    "# #     y_pred = model.predict(X_test).reshape(1, -1)[0]\n",
    "\n",
    "# #     y_preds.append(y_pred)\n",
    "#     models.append(model)\n",
    "#     model.save(f\"./ump_1dcnn_f{fold}.h5\")\n",
    "#     rmse_lst.append(valid_mse)\n",
    "#     fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182f6cd-184d-40eb-bbb6-7d42ea966a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70668ddf-1cea-4fa1-875e-97bb89bcbd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2b94e-7fcd-47eb-8c1c-6e29f03730ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182696c-8966-4a33-8c11-7326ff9467c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a64c5d-3a6e-4eb5-b192-acf5b1234348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c1e36-bb37-4e22-975b-7a88f9f917f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da065b-0374-4bbb-80ca-7ca573b533cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734aafda-2808-4481-a635-06748e03efba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad72bde-6e8c-41bf-b438-524a0239cc42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd82f2-ec23-42ad-b4f6-74b9641b04e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d98f6-2a4c-4b80-8324-ed41e407e78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc92ee-cf96-4aab-8f74-8c0ad4d0e079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe217c0-2f12-4298-ac46-12d3e85977a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd8358-ddfb-4e50-a59f-18ba2609b277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb1da6-45c2-4490-8e03-5071c52e1348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2157c9-99e4-4948-9246-06584c1d9ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835526ce-e3f3-46ed-bc54-0d6e4018e6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f994d-7fb2-4561-923f-945155c504e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716cd52a-ab51-4157-8a5b-1cb54573b585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb3844-17f5-45f0-8269-9a6deed4d507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4890a78-8f1a-4946-9367-fbcea62847cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d57c85-88bc-427a-8426-c543deef08ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194cd6b-a220-4294-9532-3014684fc59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f05973-dded-4ae6-a451-dcb7db4abfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1955885-9cc5-48e4-ac93-b019a13851cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76206e97-5742-4d0f-908b-0c34180f76db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d84fd6-1cce-49c6-978c-55d50a2e00ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8442c00-7719-4bc9-a787-4feb78c1c474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
